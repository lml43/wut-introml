{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from data_prepare import Data\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Set\n",
    "\n",
    "#### Description\n",
    "The 'Mushroom' data set includes descriptions of hypothetical samples corresponding to \n",
    "23 species of gilled mushrooms in the Agaricus and Lepiota Family (pp. 500-525). \n",
    "Each species is identified as definitely edible, definitely poisonous, or of unknown\n",
    "edibility and not recommended. This latter class was combined with the poisonous \n",
    "one. The Guide clearly states that there is no simple rule for determining \n",
    "the edibility of a mushroom. Our goal is to predict the edibility of a mushroom with the \n",
    "help of a Machine Learning model.\n",
    "\n",
    "#### Structure \n",
    "\n",
    "The Mushroom data set consists of 8124 instances with 22 categorical features.\n",
    "1. cap-shape\n",
    "2. cap-surface\n",
    "3. cap-color\n",
    "4. bruises?\n",
    "5. odor\n",
    "6. gill-attachment\n",
    "7. gill-spacing\n",
    "8. gill-size\n",
    "9. gill-color\n",
    "10. stalk-shape\n",
    "11. stalk-root\n",
    "12. stalk-surface-above-ring\n",
    "13. stalk-surface-below-ring\n",
    "14. stalk-color-above-ring\n",
    "15. stalk-color-below-ring\n",
    "16. veil-type\n",
    "17. veil-color\n",
    "18. ring-number\n",
    "19. ring-type\n",
    "20. spore-print-color\n",
    "21. population\n",
    "22. habitat"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Preparation\n",
    "\n",
    "\n",
    "Extract data from input file, convert raw text to numeric data. The need arises \n",
    "because of the categorical nature of the data features."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "att_maps = [\n",
    "{\n",
    "    'e': 0,\n",
    "    'p': 1\n",
    "},\n",
    "{\n",
    "    'b': 0,\n",
    "    'c': 1,\n",
    "    'x': 2,\n",
    "    'f': 3,\n",
    "    'k': 4,\n",
    "    's': 5\n",
    "},\n",
    "{\n",
    "    'f': 0,\n",
    "    'g': 1,\n",
    "    'y': 2,\n",
    "    's': 3\n",
    "},\n",
    "{\n",
    "    'n': 0,\n",
    "    'b': 1,\n",
    "    'c': 2,\n",
    "    'g': 3,\n",
    "    'r': 4,\n",
    "    'p': 5,\n",
    "    'u': 6,\n",
    "    'e': 7,\n",
    "    'w': 8,\n",
    "    'y': 9\n",
    "},\n",
    "{\n",
    "    't': 0,\n",
    "    'f': 1\n",
    "},\n",
    "{\n",
    "    'a': 0,\n",
    "    'l': 1,\n",
    "    'c': 2,\n",
    "    'y': 3,\n",
    "    'f': 4,\n",
    "    'm': 5,\n",
    "    'n': 6,\n",
    "    'p': 7,\n",
    "    's': 8\n",
    "},\n",
    "{\n",
    "    'a': 0,\n",
    "    'd': 1,\n",
    "    'f': 2,\n",
    "    'n': 3\n",
    "},\n",
    "{\n",
    "    'c': 0,\n",
    "    'w': 1,\n",
    "    'd': 2\n",
    "},\n",
    "{\n",
    "    'b': 0,\n",
    "    'n': 1\n",
    "},\n",
    "{\n",
    "    'k': 0,\n",
    "    'n': 1,\n",
    "    'b': 2,\n",
    "    'h': 3,\n",
    "    'g': 4,\n",
    "    'r': 5,\n",
    "    'o': 6,\n",
    "    'p': 7,\n",
    "    'u': 8,\n",
    "    'e': 9,\n",
    "    'w': 10,\n",
    "    'y': 11\n",
    "},\n",
    "{\n",
    "    'e': 0,\n",
    "    't': 1\n",
    "},\n",
    "{\n",
    "    'b': 0,\n",
    "    'c': 1,\n",
    "    'u': 2,\n",
    "    'e': 3,\n",
    "    'z': 4,\n",
    "    'r': 5,\n",
    "    '?': 6,\n",
    "},\n",
    "{\n",
    "    'f': 0,\n",
    "    'y': 1,\n",
    "    'k': 2,\n",
    "    's': 3\n",
    "},\n",
    "{\n",
    "    'f': 0,\n",
    "    'y': 1,\n",
    "    'k': 2,\n",
    "    's': 3\n",
    "},\n",
    "{\n",
    "    'n': 0,\n",
    "    'b': 1,\n",
    "    'c': 2,\n",
    "    'g': 3,\n",
    "    'o': 4,\n",
    "    'p': 5,\n",
    "    'e': 6,\n",
    "    'w': 7,\n",
    "    'y': 8\n",
    "},\n",
    "{\n",
    "    'n': 0,\n",
    "    'b': 1,\n",
    "    'c': 2,\n",
    "    'g': 3,\n",
    "    'o': 4,\n",
    "    'p': 5,\n",
    "    'e': 6,\n",
    "    'w': 7,\n",
    "    'y': 8\n",
    "},\n",
    "{\n",
    "    'p': 0,\n",
    "    'u': 1\n",
    "},\n",
    "{\n",
    "    'n': 0,\n",
    "    'o': 1,\n",
    "    'w': 2,\n",
    "    'y': 3\n",
    "},\n",
    "{\n",
    "    'n': 0,\n",
    "    'o': 1,\n",
    "    't': 2\n",
    "},\n",
    "{\n",
    "    'c': 0,\n",
    "    'e': 1,\n",
    "    'f': 2,\n",
    "    'l': 3,\n",
    "    'n': 4,\n",
    "    'p': 5,\n",
    "    's': 6,\n",
    "    'z': 7\n",
    "},\n",
    "{\n",
    "    'k': 0,\n",
    "    'n': 1,\n",
    "    'b': 2,\n",
    "    'h': 3,\n",
    "    'r': 4,\n",
    "    'o': 5,\n",
    "    'u': 6,\n",
    "    'w': 7,\n",
    "    'y': 8\n",
    "},\n",
    "{\n",
    "    'a': 0,\n",
    "    'c': 1,\n",
    "    'n': 2,\n",
    "    's': 3,\n",
    "    'v': 4,\n",
    "    'y': 5\n",
    "},\n",
    "{\n",
    "    'g': 0,\n",
    "    'l': 1,\n",
    "    'm': 2,\n",
    "    'p': 3,\n",
    "    'u': 4,\n",
    "    'w': 5,\n",
    "    'd': 6\n",
    "},\n",
    "]\n",
    "\n",
    "class DataUtils:\n",
    "    @staticmethod\n",
    "    def load_data(file_name):\n",
    "        labels = []\n",
    "        features = []\n",
    "\n",
    "        f = open(file_name, \"r\")\n",
    "\n",
    "        for x in f:\n",
    "            x = x.rstrip()\n",
    "            att_arr = x.split(',')\n",
    "            att_vec = []\n",
    "            for att_idx, att_name in enumerate(att_arr):\n",
    "                att_val = att_maps[att_idx][att_arr[att_idx]]\n",
    "                att_vec.append(att_val)\n",
    "\n",
    "            labels.append(att_vec[0])\n",
    "            features.append(att_vec[1:])\n",
    "\n",
    "        return labels, features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generate feature vectors\n",
    "\n",
    "Having the data pre-processing tools we can extract the features and normalize them."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "labels, features = Data.load_data(file_name=\"data/agaricus-lepiota.data\")\n",
    "global_labels = LabelEncoder().fit_transform(labels)\n",
    "\n",
    "# normalize feature vector\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "global_features = scaler.fit_transform(features)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train test split\n",
    "\n",
    "Here we divide the data into training and testing sets."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Train data - Total 6499, feature size 22\n",
      "Test data - Total 1625, feature size 22\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "test_size = 0.2\n",
    "\n",
    "(trainDataGlobal, testDataGlobal, trainLabelsGlobal, testLabelsGlobal) = train_test_split(\n",
    "    np.array(global_features),\n",
    "    np.array(global_labels),\n",
    "    test_size=test_size)\n",
    "print(\"Train data - Total {}, feature size {}\".format(trainDataGlobal.shape[0], trainDataGlobal.shape[1]))\n",
    "print(\"Test data - Total {}, feature size {}\".format(testDataGlobal.shape[0], testDataGlobal.shape[1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Simple classification using perceptron\n",
    "We build a multilayer perceptron with (15, 15) hidden layers and 30 as maximum iterations.\n",
    "After training we achieved 100% accuracy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "---------- Accuracy -----------\n",
      "edible : 0.9747899159663865\n",
      "poisonous : 0.9368686868686869\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "class_names = ['edible', 'poisonous']\n",
    "\n",
    "clf = Perceptron(random_state=1, max_iter=30, tol=0.001)\n",
    "# clf = MLPClassifier(solver='sgd', alpha=1e-5, learning_rate_init=0.1, verbose=10, hidden_layer_sizes=(15,15), random_state=1)\n",
    "\n",
    "# fit the training data to the model\n",
    "clf.fit(trainDataGlobal, trainLabelsGlobal)\n",
    "\n",
    "\n",
    "predictions = clf.predict(testDataGlobal)\n",
    "matrix = confusion_matrix(predictions, testLabelsGlobal)\n",
    "acc_per_cls = matrix.diagonal()/matrix.sum(axis=0)\n",
    "\n",
    "print('---------- Accuracy -----------')\n",
    "for label, acc in zip(class_names, acc_per_cls):\n",
    "    print('{} : {}'.format(label, acc))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[[812  21]\n",
      " [ 50 742]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96       833\n",
      "           1       0.97      0.94      0.95       792\n",
      "\n",
      "    accuracy                           0.96      1625\n",
      "   macro avg       0.96      0.96      0.96      1625\n",
      "weighted avg       0.96      0.96      0.96      1625\n",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(confusion_matrix(testLabelsGlobal,predictions))\n",
    "print(classification_report(testLabelsGlobal,predictions))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Other classifiers\n",
    "Aside from MLP Classifier we decided to use K-nearest Neighbors, \n",
    "Random Forest and Support Vector Machine classifiers. The cross validation results were \n",
    "similarly 100% for all of the classifiers (except KNN with 99.99%).  "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "KNN: 0.999877 (0.000246)\n",
      "RF: 1.000000 (0.000000)\n",
      "SVM: 1.000000 (0.000000)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "scoring = \"accuracy\"\n",
    "results = []\n",
    "names = []\n",
    "models = []\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('RF', RandomForestClassifier(n_estimators=100)))\n",
    "models.append(('SVM', SVC()))\n",
    "\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "    cv_results = cross_val_score(model, global_features, global_labels, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}