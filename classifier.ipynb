{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from data_prepare import Data\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Preparation\n",
    "Extract data from input file, convert raw text to numeric data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "att_maps = [\n",
    "{\n",
    "    'e': 0,\n",
    "    'p': 1\n",
    "},\n",
    "{\n",
    "    'b': 0,\n",
    "    'c': 1,\n",
    "    'x': 2,\n",
    "    'f': 3,\n",
    "    'k': 4,\n",
    "    's': 5\n",
    "},\n",
    "{\n",
    "    'f': 0,\n",
    "    'g': 1,\n",
    "    'y': 2,\n",
    "    's': 3\n",
    "},\n",
    "{\n",
    "    'n': 0,\n",
    "    'b': 1,\n",
    "    'c': 2,\n",
    "    'g': 3,\n",
    "    'r': 4,\n",
    "    'p': 5,\n",
    "    'u': 6,\n",
    "    'e': 7,\n",
    "    'w': 8,\n",
    "    'y': 9\n",
    "},\n",
    "{\n",
    "    't': 0,\n",
    "    'f': 1\n",
    "},\n",
    "{\n",
    "    'a': 0,\n",
    "    'l': 1,\n",
    "    'c': 2,\n",
    "    'y': 3,\n",
    "    'f': 4,\n",
    "    'm': 5,\n",
    "    'n': 6,\n",
    "    'p': 7,\n",
    "    's': 8\n",
    "},\n",
    "{\n",
    "    'a': 0,\n",
    "    'd': 1,\n",
    "    'f': 2,\n",
    "    'n': 3\n",
    "},\n",
    "{\n",
    "    'c': 0,\n",
    "    'w': 1,\n",
    "    'd': 2\n",
    "},\n",
    "{\n",
    "    'b': 0,\n",
    "    'n': 1\n",
    "},\n",
    "{\n",
    "    'k': 0,\n",
    "    'n': 1,\n",
    "    'b': 2,\n",
    "    'h': 3,\n",
    "    'g': 4,\n",
    "    'r': 5,\n",
    "    'o': 6,\n",
    "    'p': 7,\n",
    "    'u': 8,\n",
    "    'e': 9,\n",
    "    'w': 10,\n",
    "    'y': 11\n",
    "},\n",
    "{\n",
    "    'e': 0,\n",
    "    't': 1\n",
    "},\n",
    "{\n",
    "    'b': 0,\n",
    "    'c': 1,\n",
    "    'u': 2,\n",
    "    'e': 3,\n",
    "    'z': 4,\n",
    "    'r': 5,\n",
    "    '?': 6,\n",
    "},\n",
    "{\n",
    "    'f': 0,\n",
    "    'y': 1,\n",
    "    'k': 2,\n",
    "    's': 3\n",
    "},\n",
    "{\n",
    "    'f': 0,\n",
    "    'y': 1,\n",
    "    'k': 2,\n",
    "    's': 3\n",
    "},\n",
    "{\n",
    "    'n': 0,\n",
    "    'b': 1,\n",
    "    'c': 2,\n",
    "    'g': 3,\n",
    "    'o': 4,\n",
    "    'p': 5,\n",
    "    'e': 6,\n",
    "    'w': 7,\n",
    "    'y': 8\n",
    "},\n",
    "{\n",
    "    'n': 0,\n",
    "    'b': 1,\n",
    "    'c': 2,\n",
    "    'g': 3,\n",
    "    'o': 4,\n",
    "    'p': 5,\n",
    "    'e': 6,\n",
    "    'w': 7,\n",
    "    'y': 8\n",
    "},\n",
    "{\n",
    "    'p': 0,\n",
    "    'u': 1\n",
    "},\n",
    "{\n",
    "    'n': 0,\n",
    "    'o': 1,\n",
    "    'w': 2,\n",
    "    'y': 3\n",
    "},\n",
    "{\n",
    "    'n': 0,\n",
    "    'o': 1,\n",
    "    't': 2\n",
    "},\n",
    "{\n",
    "    'c': 0,\n",
    "    'e': 1,\n",
    "    'f': 2,\n",
    "    'l': 3,\n",
    "    'n': 4,\n",
    "    'p': 5,\n",
    "    's': 6,\n",
    "    'z': 7\n",
    "},\n",
    "{\n",
    "    'k': 0,\n",
    "    'n': 1,\n",
    "    'b': 2,\n",
    "    'h': 3,\n",
    "    'r': 4,\n",
    "    'o': 5,\n",
    "    'u': 6,\n",
    "    'w': 7,\n",
    "    'y': 8\n",
    "},\n",
    "{\n",
    "    'a': 0,\n",
    "    'c': 1,\n",
    "    'n': 2,\n",
    "    's': 3,\n",
    "    'v': 4,\n",
    "    'y': 5\n",
    "},\n",
    "{\n",
    "    'g': 0,\n",
    "    'l': 1,\n",
    "    'm': 2,\n",
    "    'p': 3,\n",
    "    'u': 4,\n",
    "    'w': 5,\n",
    "    'd': 6\n",
    "},\n",
    "]\n",
    "\n",
    "class DataUtils:\n",
    "    @staticmethod\n",
    "    def load_data(file_name):\n",
    "        labels = []\n",
    "        features = []\n",
    "\n",
    "        f = open(file_name, \"r\")\n",
    "\n",
    "        for x in f:\n",
    "            x = x.rstrip()\n",
    "            att_arr = x.split(',')\n",
    "            att_vec = []\n",
    "            for att_idx, att_name in enumerate(att_arr):\n",
    "                att_val = att_maps[att_idx][att_arr[att_idx]]\n",
    "                att_vec.append(att_val)\n",
    "\n",
    "            labels.append(att_vec[0])\n",
    "            features.append(att_vec[1:])\n",
    "\n",
    "        return labels, features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generate feature vectors"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "labels, features = Data.load_data(file_name=\"data/agaricus-lepiota.data\")\n",
    "global_labels = LabelEncoder().fit_transform(labels)\n",
    "\n",
    "# normalize feature vector\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "global_features = scaler.fit_transform(features)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train test split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data - Total 6499, feature size 22\n",
      "Test data - Total 1625, feature size 22\n"
     ]
    }
   ],
   "source": [
    "test_size = 0.2\n",
    "\n",
    "(trainDataGlobal, testDataGlobal, trainLabelsGlobal, testLabelsGlobal) = train_test_split(\n",
    "    np.array(global_features),\n",
    "    np.array(global_labels),\n",
    "    test_size=test_size)\n",
    "print(\"Train data - Total {}, feature size {}\".format(trainDataGlobal.shape[0], trainDataGlobal.shape[1]))\n",
    "print(\"Test data - Total {}, feature size {}\".format(testDataGlobal.shape[0], testDataGlobal.shape[1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Simple classification using perceptron"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Accuracy -----------\n",
      "edible : 0.8767772511848341\n",
      "poisonous : 0.9846350832266325\n"
     ]
    }
   ],
   "source": [
    "class_names = ['edible', 'poisonous']\n",
    "\n",
    "clf = Perceptron(random_state=1, max_iter=30, tol=0.001)\n",
    "# clf = MLPClassifier(solver='sgd', alpha=1e-5, learning_rate_init=0.1, verbose=10, hidden_layer_sizes=(15,15), random_state=1)\n",
    "\n",
    "# fit the training data to the model\n",
    "clf.fit(trainDataGlobal, trainLabelsGlobal)\n",
    "\n",
    "\n",
    "predictions = clf.predict(testDataGlobal)\n",
    "matrix = confusion_matrix(predictions, testLabelsGlobal)\n",
    "acc_per_cls = matrix.diagonal()/matrix.sum(axis=0)\n",
    "\n",
    "print('---------- Accuracy -----------')\n",
    "for label, acc in zip(class_names, acc_per_cls):\n",
    "    print('{} : {}'.format(label, acc))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Other classifiers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN: 0.999877 (0.000246)\n",
      "RF: 1.000000 (0.000000)\n",
      "SVM: 1.000000 (0.000000)\n"
     ]
    }
   ],
   "source": [
    "scoring = \"accuracy\"\n",
    "results = []\n",
    "names = []\n",
    "models = []\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('RF', RandomForestClassifier(n_estimators=100)))\n",
    "models.append(('SVM', SVC()))\n",
    "\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "    cv_results = cross_val_score(model, global_features, global_labels, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}